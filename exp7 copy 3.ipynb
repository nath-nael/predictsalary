{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6196dee1",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a357fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e305ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b744d3",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61d58d",
   "metadata": {},
   "source": [
    "Preprocessing : Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bf26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)\": \"Salary\",\n",
    "    \"How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.\": \"AdditionalComp\",\n",
    "    \"Please indicate the currency\": \"Currency\",\n",
    "    \"How old are you?\": \"Age\",\n",
    "    \"What industry do you work in?\": \"Industry\",\n",
    "    \"Job title\": \"JobTitle\",\n",
    "    \"What country do you work in?\": \"Country\",\n",
    "    \"How many years of professional work experience do you have overall?\": \"ExperienceOverall\",\n",
    "    \"How many years of professional work experience do you have in your field?\": \"ExperienceField\",\n",
    "    \"What is your highest level of education completed?\": \"Education\",\n",
    "    \"What is your gender?\": \"Gender\",\n",
    "    \"What is your race? (Choose all that apply.)\": \"Race\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a57df",
   "metadata": {},
   "source": [
    "Preprocessing : String to Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51935a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Salary\"] = df[\"Salary\"].str.replace(\",\", \"\").astype(float)\n",
    "df[\"AdditionalComp\"] = df[\"AdditionalComp\"].astype(str).str.replace(\",\", \"\").replace(\"nan\", None)\n",
    "df[\"AdditionalComp\"] = pd.to_numeric(df[\"AdditionalComp\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8006a5be",
   "metadata": {},
   "source": [
    "Preprocessing : Set Currency to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458cb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_rates = {\n",
    "    'USD': 1.0,\n",
    "    'GBP': 1.25,\n",
    "    'EUR': 1.08,\n",
    "    'CAD': 0.74,\n",
    "    'AUD': 0.66,\n",
    "    'INR': 0.012,\n",
    "    'JPY': 0.0065,\n",
    "    'SGD': 0.74,\n",
    "    'MYR': 0.21,\n",
    "    'IDR': 0.000065,\n",
    "    \n",
    "}\n",
    "\n",
    "def convert_to_usd(row):\n",
    "    rate = currency_rates.get(row['Currency'], None)\n",
    "    if rate is not None:\n",
    "        row['Salary'] = row['Salary'] * rate\n",
    "        if not pd.isna(row['AdditionalComp']):\n",
    "            row['AdditionalComp'] = row['AdditionalComp'] * rate\n",
    "        row['Currency'] = 'USD'\n",
    "    return row\n",
    "\n",
    "df = df.apply(convert_to_usd, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a62e0",
   "metadata": {},
   "source": [
    "Preprocessing : Processing Multivariant Country Free Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29918ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country_cleaned'] = df['Country'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33f27b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "unique_locations = df[\"Country\"].unique()\n",
    "\n",
    "\n",
    "replacements = {\n",
    "    'United States': [\n",
    "        r'\\bU\\.?S\\.?A?\\.?\\b', r'\\bU\\.S\\.A\\.?\\b', r'\\bU\\.S\\.?\\.?\\b',\n",
    "        r'\\bUsa\\b', r'\\bus\\b', r'\\bUS\\b', r'\\bUnited States\\b',\n",
    "        r'\\bUnited states\\b', r'\\bUnited states of america\\b',\n",
    "        r'\\bUnited States of America\\b', r'\\bAmerica\\b',\n",
    "        r'\\bUnited Stated\\b', r'\\bUnited Statws\\b', r'\\bUnited Statues\\b',\n",
    "        r'\\bUnited Stattes\\b', r'\\bUnited Statea\\b', r'\\bUSA\\b',\n",
    "        r'\\busa\\b', r'\\bUNITED STATES\\b', r'\\bunited states\\b',\n",
    "        r'\\bUnitedStates\\b', r'\\bUnited STates\\b', r'\\bUntied States\\b',\n",
    "        r'\\bUnites States\\b', r'\\bUnited State\\b', r'\\bUnited Sates\\b',\n",
    "        r'\\bUnite States\\b', r'\\bUnitef Stated\\b', r'\\bUnited Statss\\b',\n",
    "        r'\\bUnited States is America\\b', r'\\bUS of A\\b', r'\\bUnited y\\b',\n",
    "        r'\\bUSAB\\b', r'\\bUnited Stares\\b', r'\\bUSA tomorrow\\b',\n",
    "        r'\\bU\\. S\\.?\\b', r'\\bU\\.A\\.\\b', r'\\bU\\.S>\\b', r'\\bUSS\\b',\n",
    "        r'\\bUSA-- Virgin Islands\\b', r'\\bUSaa\\b', r'\\buSA\\b',\n",
    "        r'\\bUsa \\b', r'\\bUnited States of American\\b',\n",
    "        r'\\bUnited States Of America\\b'\n",
    "    ],\n",
    "    'United Kingdom': [\n",
    "        r'\\bUK\\b', r'\\buk\\b', r'\\bUk\\b', r'\\bU\\.K\\.?\\b',\n",
    "        r'\\bUnited Kingdom\\b', r'\\bEngland\\b', r'\\bGreat Britain\\b',\n",
    "        r'\\bScotland\\b', r'\\bWales\\b', r'\\bEngland/UK\\b',\n",
    "        r'\\bUnited Kindom\\b', r'\\bUnited Kingdomk\\b', r'\\bU\\.K. \\(northern England\\)\\b',\n",
    "        r'\\bEngland, UK\\b', r'\\bEngland, United Kingdom\\b',\n",
    "        r'\\bEngland, United Kingdom \\b', r'\\bEngland, Gb\\b',\n",
    "        r'\\bNorthern Ireland\\b', r'\\bUK \\(Northern Ireland\\)\\b',\n",
    "        r'\\bUnited kingdom\\b', r'\\bUnited kingdom \\b', r'\\bunited kingdom\\b',\n",
    "        r'\\bScotland, UK\\b', r'\\bWales \\(United Kingdom\\)\\b',\n",
    "        r'\\bUK, remote\\b', r'\\bUK, but for globally fully remote company\\b',\n",
    "        r'\\bUK \\(England\\)\\b'\n",
    "    ],\n",
    "    'Canada': [\n",
    "        r'\\bCanada\\b', r'\\bcanada\\b', r'\\bCanada, Ottawa, ontario\\b',\n",
    "        r'\\bCanada and USA\\b', r'\\bCANADA\\b', r'\\bCANADA \\b',\n",
    "        r'\\bCanadw\\b', r'\\bCsnada\\b', r'\\bCanad\\b', r'\\bCanadÃ¡\\b'\n",
    "    ],\n",
    "    'Australia': [\n",
    "        r'\\bAustralia\\b', r'\\bAustralia \\b', r'\\baustralia\\b',\n",
    "        r'\\bAustrali\\b', r'\\bAustralian \\b'\n",
    "    ],\n",
    "    'Netherlands': [\n",
    "        r'\\bThe Netherlands\\b', r'\\bthe Netherlands\\b', r'\\bNetherlands\\b',\n",
    "        r'\\bnetherlands\\b', r'\\bNetherlands \\b', r'\\bThe Netherlands \\b',\n",
    "        r'\\bNederland\\b', r'\\bNL\\b'\n",
    "    ],\n",
    "    'Germany': [\n",
    "        r'\\bGermany\\b', r'\\bGermany \\b', r'\\bgermany\\b'\n",
    "    ],\n",
    "    'India': [\n",
    "        r'\\bIndia\\b', r'\\bindia\\b', r'\\bINDIA\\b', r'\\bibdia\\b'\n",
    "    ],\n",
    "    'France': [\n",
    "        r'\\bFrance\\b', r'\\bFRANCE\\b', r'\\bfrance\\b', r'\\bFrance \\b'\n",
    "    ],\n",
    "    'Mexico': [\n",
    "        r'\\bMexico\\b', r'\\bMexico \\b', r'\\bMÃ©xico\\b'\n",
    "    ],\n",
    "    'New Zealand': [\n",
    "        r'\\bNew Zealand\\b', r'\\bNew zealand\\b', r'\\bNZ\\b',\n",
    "        r'\\bNew Zealand Aotearoa\\b', r'\\bAotearoa New Zealand\\b',\n",
    "        r'\\bFrom New Zealand but on projects across APAC\\b'\n",
    "    ],\n",
    "    'Singapore': [\n",
    "        r'\\bSingapore\\b', r'\\bsingapore\\b', r'\\bSingapore \\b'\n",
    "    ],\n",
    "    'HongKong':[\n",
    "        r'\\bHong KongKong\\b'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def normalize_location(loc):\n",
    "    for standard, patterns in replacements.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, loc, re.IGNORECASE):\n",
    "                return standard\n",
    "    return loc.strip()\n",
    "\n",
    "normalized_locations = [normalize_location(loc) for loc in unique_locations]\n",
    "unique_normalized_locations = sorted(set(normalized_locations))\n",
    "\n",
    "df['Country_cleaned'] = df['Country'].apply(normalize_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf5297",
   "metadata": {},
   "source": [
    "Preprocessing : Processing Multivariant Country with Fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60205ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989c6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_countries = [country.name for country in pycountry.countries]\n",
    "valid_countries += ['United States', 'United Kingdom']  \n",
    "\n",
    "def regex_normalize(loc):\n",
    "    for standard, patterns in replacements.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, loc, re.IGNORECASE):\n",
    "                return standard\n",
    "    return None  # Not found\n",
    "\n",
    "def fuzzy_match_country(loc, threshold=85):\n",
    "    match = process.extractOne(loc, valid_countries, scorer=fuzz.ratio)\n",
    "    if match and match[1] >= threshold:\n",
    "        return match[0]\n",
    "    return None\n",
    "\n",
    "def normalize_location_full(loc):\n",
    "    if not isinstance(loc, str):\n",
    "        return None\n",
    "    loc = loc.strip()\n",
    "    \n",
    "    norm = regex_normalize(loc)\n",
    "    if norm:\n",
    "        return norm\n",
    "    \n",
    "    return fuzzy_match_country(loc)\n",
    "\n",
    "df['Country_cleaned'] = df['Country'].astype(str).apply(normalize_location_full)\n",
    "\n",
    "df = df[df['Country_cleaned'].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbdeba",
   "metadata": {},
   "source": [
    "Preprocessing : Generalizing Multivariant Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705c0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry_grouped\n",
      "Tech                           9390\n",
      "Education                      3764\n",
      "Finance                        2351\n",
      "Healthcare                     2099\n",
      "Government                     1917\n",
      "Engineering & Manufacturing    1768\n",
      "Marketing                      1426\n",
      "Legal                          1097\n",
      "Other                           944\n",
      "Consulting                      891\n",
      "Retail                          515\n",
      "Construction & Real Estate      450\n",
      "Art & Design                    370\n",
      "Media & Entertainment           337\n",
      "Logistics                       315\n",
      "Nonprofit                       274\n",
      "Agriculture                     138\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Industry_cleaned'] = df['Industry'].str.strip().str.lower().fillna('')\n",
    "\n",
    "def map_industry(industry):\n",
    "    if any(x in industry for x in ['tech', 'software', 'it', 'developer', 'data', 'cyber']):\n",
    "        return 'Tech'\n",
    "    elif any(x in industry for x in ['finance', 'bank', 'accounting', 'investment', 'insurance']):\n",
    "        return 'Finance'\n",
    "    elif any(x in industry for x in ['health', 'hospital', 'medical', 'clinic', 'nurse', 'pharma']):\n",
    "        return 'Healthcare'\n",
    "    elif any(x in industry for x in ['education', 'school', 'university', 'teaching', 'academic', 'library', 'libraries','science', 'research']):\n",
    "        return 'Education'\n",
    "    elif any(x in industry for x in ['government', 'public administration', 'military']):\n",
    "        return 'Government'\n",
    "    elif any(x in industry for x in ['nonprofit', 'ngo', 'charity', 'social']):\n",
    "        return 'Nonprofit'\n",
    "    elif any(x in industry for x in ['retail', 'ecommerce', 'shopping', 'fashion']):\n",
    "        return 'Retail'\n",
    "    elif any(x in industry for x in ['media', 'entertainment', 'music', 'film','publishing']):\n",
    "        return 'Media & Entertainment'\n",
    "    elif any(x in industry for x in ['law', 'legal', 'attorney']):\n",
    "        return 'Legal'\n",
    "    elif any(x in industry for x in ['construction', 'real estate', 'architecture']):\n",
    "        return 'Construction & Real Estate'\n",
    "    elif any(x in industry for x in ['consulting', 'strategy', 'business']):\n",
    "        return 'Consulting'\n",
    "    elif any(x in industry for x in ['manufacturing', 'engineering', 'mechanical']):\n",
    "        return 'Engineering & Manufacturing'\n",
    "    elif any(x in industry for x in ['transport', 'logistics', 'supply chain']):\n",
    "        return 'Logistics'\n",
    "    elif any(x in industry for x in ['marketing','advertising','sales']):\n",
    "        return 'Marketing'\n",
    "    elif any(x in industry for x in ['art', 'design']):\n",
    "        return 'Art & Design'\n",
    "    elif any(x in industry for x in ['agriculture', 'forestry']):\n",
    "        return 'Agriculture'\n",
    "    \n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['Industry_grouped'] = df['Industry_cleaned'].apply(map_industry)\n",
    "\n",
    "print(df['Industry_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45aa5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JobTitle_cleaned'] = df['JobTitle'].astype(str).str.strip().str.lower().fillna('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb959e",
   "metadata": {},
   "source": [
    "Preprocessing : Generalizing Multivariant Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6656d145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobTitle_grouped\n",
       "Management                      9216\n",
       "Executive                       4490\n",
       "Engineering & IT                4103\n",
       "Education & Training            1620\n",
       "Data & Analytics                1606\n",
       "Administrative                  1220\n",
       "Other                           1146\n",
       "Marketing & Communications       992\n",
       "Legal                            514\n",
       "Consulting                       512\n",
       "Strategist                       502\n",
       "Healthcare                       440\n",
       "Creative Arts                    331\n",
       "Finance & Accounting             282\n",
       "Human Resources                  265\n",
       "Project & Program Management     247\n",
       "Assistant                        140\n",
       "Sales                            107\n",
       "Researcher & Scientist           100\n",
       "Intern                            71\n",
       "Customer Service                  67\n",
       "News & Media                      42\n",
       "Entrepreneur                      17\n",
       "Language Expert                   16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_job_title(title):\n",
    "    title = str(title).lower()\n",
    "    if any(x in title for x in ['ceo', 'cfo','cto','director','chief', 'executive', 'president', 'vp', 'vice','head']):\n",
    "        return 'Executive'\n",
    "    elif any(x in title for x in ['coordinator','manager', 'supervisor', 'lead','senior']):\n",
    "        return 'Management'\n",
    "    elif any(x in title for x in ['computer','agile','scrum','engineer', 'developer', 'programmer', 'software', 'tech', 'technician', 'it']):\n",
    "        return 'Engineering & IT'\n",
    "    elif any(x in title for x in ['data', 'analyst', 'scientist', 'analytics','statistician']):\n",
    "        return 'Data & Analytics'\n",
    "    elif any(x in title for x in ['designer','artist','graphic','design']):\n",
    "        return 'Creative Arts'\n",
    "    elif any(x in title for x in ['school','teaching','Bookkeeper','lecturer','library','librarian','teacher', 'instructor', 'educator', 'professor', 'tutor', 'trainer', 'instructional','education','research']):\n",
    "        return 'Education & Training'\n",
    "    elif any(x in title for x in ['outreach','pr','marketing', 'brand', 'communications', 'content', 'seo','reporter']):\n",
    "        return 'Marketing & Communications'\n",
    "    elif any(x in title for x in ['sales', 'account executive', 'business development']):\n",
    "        return 'Sales'\n",
    "    elif any(x in title for x in ['hr', 'human resources', 'recruiter', 'talent']):\n",
    "        return 'Human Resources'\n",
    "    elif any(x in title for x in ['archivist','admin', 'administrative', 'office', 'clerk','associate']):\n",
    "        return 'Administrative'\n",
    "    elif any(x in title for x in ['risk','payroll','finance', 'accounting', 'accountant', 'cpa', 'auditor','economist','buyer']):\n",
    "        return 'Finance & Accounting'\n",
    "    elif any(x in title for x in ['legal', 'lawyer', 'attorney', 'paralegal','compliance','advocate']):\n",
    "        return 'Legal'\n",
    "    elif any(x in title for x in ['dental','clinician','surgeon','clinical','psychiatrist','veterinary','optometrist','veterinarian','pharmacist','nurse', 'doctor', 'physician', 'medical', 'health','therapist']):\n",
    "        return 'Healthcare'\n",
    "    elif any(x in title for x in ['counsel','consultant', 'consulting', 'advisor','psychologist','adviser']):\n",
    "        return 'Consulting'\n",
    "    elif any(x in title for x in ['customer service', 'support', 'help desk']):\n",
    "        return 'Customer Service'\n",
    "    elif any(x in title for x in ['producer','project', 'program','partner','assistant']):\n",
    "        return 'Project & Program Management'\n",
    "    elif any(x in title for x in ['owner']):\n",
    "        return 'Entrepreneur'\n",
    "    elif any(x in title for x in ['biologist', 'epidemiologist','geologist','archaeologist','biostatistician','chemist','astronomer','sciences','ecologist','scientific']):\n",
    "        return 'Researcher & Scientist'\n",
    "    elif any(x in title for x in ['journalist','reporter','media','author']):\n",
    "        return 'News & Media'\n",
    "    elif any(x in title for x in ['translator']):\n",
    "        return 'Language Expert'\n",
    "    elif any(x in title for x in ['assistant','controller','worker']):\n",
    "        return 'Assistant'\n",
    "    elif any(x in title for x in ['intern','student']):\n",
    "        return 'Intern'\n",
    "    elif any(x in title for x in ['planner','strategist','planning','investigator','predictor','specialist','tester']):\n",
    "        return 'Strategist'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['JobTitle_grouped'] = df['JobTitle_cleaned'].apply(map_job_title)\n",
    "\n",
    "df['JobTitle_grouped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c2297",
   "metadata": {},
   "source": [
    "Preprocessing : Filtering Columns to Make It Simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb9c19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"Age\",\"Industry_grouped\",\"JobTitle_grouped\",\"Salary\",\"AdditionalComp\",\"Country_cleaned\",\"ExperienceOverall\",\"ExperienceField\",\"Education\",\"Gender\",\"Race\"]\n",
    "df = df[selected_columns]\n",
    "# df = df[df[\"Country_cleaned\"]==\"United States\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa78e58",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3430de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28046 entries, 0 to 28135\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                28046 non-null  object \n",
      " 1   Industry_grouped   28046 non-null  object \n",
      " 2   JobTitle_grouped   28046 non-null  object \n",
      " 3   Salary             28046 non-null  float64\n",
      " 4   AdditionalComp     20743 non-null  float64\n",
      " 5   Country_cleaned    28046 non-null  object \n",
      " 6   ExperienceOverall  28046 non-null  object \n",
      " 7   ExperienceField    28046 non-null  object \n",
      " 8   Education          27824 non-null  object \n",
      " 9   Gender             27875 non-null  object \n",
      " 10  Race               27866 non-null  object \n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 2.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdditionalComp       7303\n",
       "Education             222\n",
       "Race                  180\n",
       "Gender                171\n",
       "Age                     0\n",
       "Industry_grouped        0\n",
       "JobTitle_grouped        0\n",
       "Salary                  0\n",
       "Country_cleaned         0\n",
       "ExperienceOverall       0\n",
       "ExperienceField         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af32a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66389195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df['Salary'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f83cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df['AdditionalComp'].dropna(), kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "559c77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Age'].value_counts(normalize=True).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a6758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data=df, x='Age', y='Salary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6fb85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# top_jobs = df['JobTitle_grouped'].value_counts().head(10).index\n",
    "# sns.boxplot(data=df[df['JobTitle_grouped'].isin(top_jobs)], x='JobTitle_grouped', y='Salary')\n",
    "# plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9584f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data=df, x='Education', y='Salary')\n",
    "# plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d97578d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data=df, x='ExperienceOverall', y='Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070464a",
   "metadata": {},
   "source": [
    "Preprocessing : Handle Missing Values with 0 for Numerical, and Mode for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dd76101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AdditionalComp\"] = df[\"AdditionalComp\"].fillna(0)\n",
    "df[\"Education\"] = df[\"Education\"].fillna(df[\"Education\"].mode().iloc[0])\n",
    "df[\"Gender\"] = df[\"Gender\"].fillna(df[\"Gender\"].mode().iloc[0])\n",
    "df[\"Race\"] = df[\"Race\"].fillna(df[\"Race\"].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5a7e8",
   "metadata": {},
   "source": [
    "Preprocessing : Encoding High Cardinality Features with Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0089ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Industry_grouped  JobTitle_grouped   Salary  AdditionalComp  \\\n",
      "0  25-34      3.797652e+05     182384.388802  55000.0             0.0   \n",
      "1  25-34      1.270474e+05     236211.991702  68250.0          5000.0   \n",
      "2  25-34      1.995909e+06      82985.935897  34000.0             0.0   \n",
      "3  25-34      1.270474e+05     236211.991702  62000.0          3000.0   \n",
      "4  25-34      1.995909e+06     236211.991702  60000.0          7000.0   \n",
      "\n",
      "   Country_cleaned ExperienceOverall ExperienceField        Education  \\\n",
      "0    101854.580441         5-7 years       5-7 years  Master's degree   \n",
      "1     67870.762861      8 - 10 years       5-7 years   College degree   \n",
      "2    101854.580441       2 - 4 years     2 - 4 years   College degree   \n",
      "3    101854.580441      8 - 10 years       5-7 years   College degree   \n",
      "4    101854.580441      8 - 10 years       5-7 years   College degree   \n",
      "\n",
      "       Gender           Race  TotalComp  \n",
      "0       Woman  139702.284823    55000.0  \n",
      "1  Non-binary  139702.284823    73250.0  \n",
      "2       Woman  139702.284823    34000.0  \n",
      "3       Woman  139702.284823    65000.0  \n",
      "4       Woman  139702.284823    67000.0  \n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "high_card_cols = ['Industry_grouped', 'JobTitle_grouped', 'Country_cleaned',\"Race\"]\n",
    "df['TotalComp'] = df['Salary'] + df['AdditionalComp']\n",
    "encoder = ce.TargetEncoder(cols=high_card_cols)\n",
    "df_encoded = encoder.fit_transform(df[high_card_cols], df['TotalComp'])\n",
    "\n",
    "df[high_card_cols] = df_encoded\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1ac3c",
   "metadata": {},
   "source": [
    "Preprocessing : Encoding Ordinal Features with OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4c25e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  ExperienceOverall  ExperienceField  Education\n",
      "0  2.0                2.0              2.0        3.0\n",
      "1  2.0                3.0              2.0        2.0\n",
      "2  2.0                1.0              1.0        2.0\n",
      "3  2.0                3.0              2.0        2.0\n",
      "4  2.0                3.0              2.0        2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Define the custom order for each ordinal column\n",
    "age_order = ['under 18', '18-24', '25-34', '35-44', '45-54', '55-64', '65 or over']\n",
    "experience_order = [\n",
    "    '1 year or less', '2 - 4 years', '5-7 years', '8 - 10 years',\n",
    "    '11 - 20 years', '21 - 30 years', '31 - 40 years', '41 years or more'\n",
    "]\n",
    "education_order = [\n",
    "    'High School', 'Some college', 'College degree', \"Master's degree\",\n",
    "    'Professional degree (MD, JD, etc.)', 'PhD'\n",
    "]\n",
    "\n",
    "# Specify the columns and corresponding categories in order\n",
    "ordinal_cols = ['Age', 'ExperienceOverall', 'ExperienceField', 'Education']\n",
    "categories = [age_order, experience_order, experience_order, education_order]\n",
    "\n",
    "# Initialize and apply the OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=categories)\n",
    "df[ordinal_cols] = encoder.fit_transform(df[ordinal_cols])\n",
    "\n",
    "# Result\n",
    "print(df[ordinal_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8210422",
   "metadata": {},
   "source": [
    "Preprocessing : Encoding Gender Feature with OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e5eb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Gender'], prefix='Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d203a12",
   "metadata": {},
   "source": [
    "Preprocessing : Binning Salary & Additional Compensation to Increase Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "899c4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary_binned'] = pd.qcut(df['Salary'], q=5, labels=False)\n",
    "df['AdditionalComp_binned'] = pd.cut(df['AdditionalComp'], bins=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c8db5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori dan range:\n",
      "IntervalIndex([(-0.001, 50000.0], (50000.0, 65100.0], (65100.0, 85000.0], (85000.0, 120000.0], (120000.0, 4440051800.0]], dtype='interval[float64, right]')\n"
     ]
    }
   ],
   "source": [
    "bins = pd.qcut(df['Salary'], q=5)\n",
    "\n",
    "print(\"Kategori dan range:\")\n",
    "print(bins.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "247bf594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori dan range:\n",
      "IntervalIndex([(-120000.0, 24000000.0], (24000000.0, 48000000.0], (48000000.0, 72000000.0], (72000000.0, 96000000.0], (96000000.0, 120000000.0]], dtype='interval[float64, right]')\n"
     ]
    }
   ],
   "source": [
    "bins = pd.cut(df['AdditionalComp'], bins=5)\n",
    "\n",
    "print(\"Kategori dan range:\")\n",
    "print(bins.cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c759c",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e419d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b159d",
   "metadata": {},
   "source": [
    "Model : Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f49f8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Salary', 'AdditionalComp', 'TotalComp', 'Salary_binned', 'AdditionalComp_binned'])\n",
    "y = df[['Salary_binned', 'AdditionalComp_binned']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4911a",
   "metadata": {},
   "source": [
    "Model : Normalization with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82c819fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec3e7b",
   "metadata": {},
   "source": [
    "Model : Dimensional Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e856d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a037bd",
   "metadata": {},
   "source": [
    "Model : Model and Grid Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1169cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning GradientBoosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "4 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py\", line 274, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py\", line 63, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 669, in fit\n",
      "    y = self._encode_y(y=y, sample_weight=None)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 1532, in _encode_y\n",
      "    raise ValueError(\n",
      "ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\natha\\Downloads\\Computational_Physics\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Salary Accuracy  AdditionalComp Accuracy  Avg Accuracy\n",
      "RandomForest             0.324599                      1.0      0.662299\n",
      "GradientBoosting         0.320677                      1.0      0.660339\n"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        \"estimator__n_estimators\": [50, 100],\n",
    "        \"estimator__max_depth\": [None, 10],\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"estimator__n_estimators\": [50, 100],\n",
    "        \"estimator__learning_rate\": [0.05, 0.1],\n",
    "    },\n",
    "    # \"XGBoost\": {\n",
    "    #     \"estimator__n_estimators\": [50, 100],\n",
    "    #     \"estimator__learning_rate\": [0.05, 0.1],\n",
    "    #     \"estimator__max_depth\": [3, 6],\n",
    "    # }\n",
    "}\n",
    "\n",
    "base_models = {\n",
    "    \"RandomForest\": MultiOutputClassifier(RandomForestClassifier(random_state=42)),\n",
    "    \"GradientBoosting\": MultiOutputClassifier(GradientBoostingClassifier(random_state=42)),\n",
    "    # \"XGBoost\": MultiOutputClassifier(XGBClassifier(random_state=42, verbosity=0)),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "for name, base_model in base_models.items():\n",
    "    print(f\"Tuning {name}...\")\n",
    "    grid = GridSearchCV(base_model, param_grids[name], cv=3, n_jobs=-1, scoring='accuracy')\n",
    "    grid.fit(X_train_pca, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    trained_models[name] = best_model\n",
    "    y_pred = best_model.predict(X_test_pca)\n",
    "\n",
    "    salary_acc = accuracy_score(y_test['Salary_binned'], y_pred[:, 0])\n",
    "    addcomp_acc = accuracy_score(y_test['AdditionalComp_binned'], y_pred[:, 1])\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Salary Accuracy\": salary_acc,\n",
    "        \"AdditionalComp Accuracy\": addcomp_acc,\n",
    "        \"Avg Accuracy\": (salary_acc + addcomp_acc) / 2\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7afaa3",
   "metadata": {},
   "source": [
    "Evaluation : Accuracy Score and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e93e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: RandomForest\n",
      "Best accuracy: 0.6623\n",
      "=== Salary Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.41      0.42      1196\n",
      "           1       0.25      0.23      0.24      1018\n",
      "           2       0.22      0.22      0.22      1129\n",
      "           3       0.28      0.30      0.29      1159\n",
      "           4       0.44      0.44      0.44      1108\n",
      "\n",
      "    accuracy                           0.32      5610\n",
      "   macro avg       0.32      0.32      0.32      5610\n",
      "weighted avg       0.32      0.32      0.32      5610\n",
      "\n",
      "=== Additional Compensation Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5610\n",
      "\n",
      "    accuracy                           1.00      5610\n",
      "   macro avg       1.00      1.00      1.00      5610\n",
      "weighted avg       1.00      1.00      1.00      5610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df[\"Avg Accuracy\"] = (results_df[\"Salary Accuracy\"] + results_df[\"AdditionalComp Accuracy\"])/2\n",
    "best_model_name = results_df['Avg Accuracy'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "print(f\"Best accuracy: {results_df.loc[best_model_name, 'Avg Accuracy']:.4f}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test_pca)\n",
    "\n",
    "print(\"=== Salary Classification Report ===\")\n",
    "print(classification_report(y_test['Salary_binned'], y_pred[:, 0]))\n",
    "\n",
    "print(\"=== Additional Compensation Classification Report ===\")\n",
    "print(classification_report(y_test['AdditionalComp_binned'], y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8912f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8eb7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(cols=high_card_cols)\n",
    "df_encoded = target_encoder.fit_transform(df[high_card_cols], df['TotalComp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a41f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62086015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model components...\n",
      "â Model saved\n",
      "â Scaler saved\n",
      "â PCA saved\n",
      "â Target encoder saved\n",
      "â Ordinal encoder saved\n",
      "â Metadata saved\n",
      "Warning: Could not save combined file: name 'category_encoders' is not defined\n",
      "Individual component files are saved and can be used instead.\n",
      "\n",
      "All components saved successfully!\n",
      "Best model: RandomForest\n",
      "Best accuracy: 0.6623\n",
      "You can now use the Streamlit app for predictions!\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "# === SAVE ALL COMPONENTS ===\n",
    "# Save components individually to avoid pickle issues\n",
    "print(\"\\nSaving model components...\")\n",
    "\n",
    "# Save the main model\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"â Model saved\")\n",
    "\n",
    "# Save scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"â Scaler saved\")\n",
    "\n",
    "# Save PCA\n",
    "with open(\"pca.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "print(\"â PCA saved\")\n",
    "\n",
    "# Save target encoder\n",
    "with open(\"target_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(target_encoder, f)\n",
    "print(\"â Target encoder saved\")\n",
    "\n",
    "# Save ordinal encoder\n",
    "with open(\"ordinal_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ordinal_encoder, f)\n",
    "print(\"â Ordinal encoder saved\")\n",
    "\n",
    "# Save metadata (feature columns, results, etc.)\n",
    "metadata = {\n",
    "    'feature_columns': list(X.columns),\n",
    "    'results': results,\n",
    "    'best_model_name': best_model_name,\n",
    "    'target_columns': ['Salary_binned', 'AdditionalComp_binned'],\n",
    "    'high_card_cols': high_card_cols,\n",
    "    'ordinal_cols': ordinal_cols,\n",
    "    'categories': {\n",
    "        'age_order': age_order,\n",
    "        'experience_order': experience_order, \n",
    "        'education_order': education_order\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"model_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(\"â Metadata saved\")\n",
    "\n",
    "# Create a combined components file (alternative approach)\n",
    "try:\n",
    "    model_components = {\n",
    "        'model': best_model,\n",
    "        'scaler': scaler,\n",
    "        'pca': pca,\n",
    "        'target_encoder': category_encoders,\n",
    "        'ordinal_encoder': OrdinalEncoder,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "    \n",
    "    with open(\"model_components.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model_components, f)\n",
    "    print(\"â Combined components file saved\")\n",
    "    \n",
    "    # Verify the saved model works\n",
    "    print(\"\\nVerifying saved model...\")\n",
    "    with open(\"model_components.pkl\", \"rb\") as f:\n",
    "        loaded_components = pickle.load(f)\n",
    "    \n",
    "    # Test prediction on one sample\n",
    "    test_pred = loaded_components['model'].predict(X_test_pca[:1])\n",
    "    print(f\"Test prediction: Salary tier {test_pred[0][0]}, AddComp tier {test_pred[0][1]}\")\n",
    "    print(\"â Model verification successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save combined file: {e}\")\n",
    "    print(\"Individual component files are saved and can be used instead.\")\n",
    "\n",
    "print(f\"\\nAll components saved successfully!\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best accuracy: {results_df.loc[best_model_name, 'Avg Accuracy']:.4f}\")\n",
    "print(\"You can now use the Streamlit app for predictions!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
